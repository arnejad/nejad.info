<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1, shrink-to-fit=no"
    />
    <meta name="description" content="Ashkan Nejad" />
    <meta name="author" content="Ashkan Nejad" />
    <link
      href="https://fonts.googleapis.com/css?family=Lato:100,300,400,700,900"
      rel="stylesheet"
    />

    <title>Ashkan Nejad</title>
<!--
Reflux Template
https://templatemo.com/tm-531-reflux
-->
    <!-- Bootstrap core CSS -->
    <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet" />

    <!-- Additional CSS Files -->
    <link rel="stylesheet" href="assets/css/fontawesome.css" />
    <link rel="stylesheet" href="assets/css/templatemo-style.css" />
    <link rel="stylesheet" href="assets/css/owl.css" />
    <link rel="stylesheet" href="assets/css/lightbox.css" />
  </head>

  <body>
    <div id="page-wraper">
      <!-- Sidebar Menu -->
      <div class="responsive-nav">
        <i class="fa fa-bars" id="menu-toggle"></i>
        <div id="menu" class="menu">
          <i class="fa fa-times" id="menu-close"></i>
          <div class="container">
            <div class="image">
              <a href="#"><img src="assets/images/profile.jpg" alt="" /></a>
            </div>
            <div class="author-content">
                <h4 style="color: white;">Ashkan Nejad</h4>
                <span>Research Associate at Royal Dutch Visio</span>
                <span><br><a href="mailto:AshkanNejad@visio.org">AshkanNejad@visio.org</a></span>
              </div>
            <nav class="main-nav" role="navigation">
              <ul class="main-menu">
                <li><a href="/">About Me</a></li>
                <li class="active"><a href="projects.html">Projects</a></li>
                <li><a href="students.html">Students</a></li>
                <li><a href="contents.html">Contents</a></li>
                <li><a href="contact.html">Contact Me</a></li>
              </ul>
            </nav>
            <div class="social-network">
              <ul class="soial-icons">
                <li>
                  <a href="https://www.linkedin.com/in/arnejad/"><i class="fa fa-linkedin"></i></a>
                </li>
                <li>
                  <a href="https://github.com/arnejad"><i class="fa fa-github"></i></a>
                </li>
              </ul>
            </div>
            <!-- <div class="copyright-text">
              <p>Website design by Reflux Design</p>
            </div> -->
          </div>
        </div>
      </div>
      <section class="section" data-section="aboutme" style="margin-top: 50px; margin-bottom: 100px;">
        <div class="container">
          <div class="section-heading" >
            <h2>Project</h2>
            <span>
                Below, you can find the projects that I have been involved in.
            </span>
          </div>

          
          <div class="left-image-post">
            <div class="row">
              <div class="col-md-4">
                <div class="left-image">
                  <img src="assets/images/gazeshift.jpg" alt="gaze shift" />
                </div>
                <div style="margin-top: 10px;">
                  <a href="https://www.visio.org/en-gb/professional/expertise/onderzoeken">
                    <img src="assets/images/logos/visio.png" style="width: 90px;" alt="visio" />
                  </a>
                  <a href="https://vu.nl/en?slug=nl">
                    <img src="assets/images/logos/VU-logo-RGB.png" style="width: 110px;" alt="VU" />
                  </a>
                </div>
              </div>
              <div class="col-md-8">
                <div class="right-text">
                  <h4>Detecting Gaze Shifts of Moving Observers in Dynamic Environments</h4>
                  <p style="margin-top: 0px">Ashkan Nejad, 
                    <a href="https://www.researchgate.net/profile/Andrea-Ghiani">Andrea Ghiani</a>,
                    <a href="https://www.rug.nl/staff/f.w.cornelissen/">Frans W. Cornelissen</a>,
                    <a href="https://personal.fgb.vu.nl/~ebrenner/">Eli Brenner</a></p>
                  <p>
                   We systematically evaluated gaze shift detection methods for mobile eye-tracking in real-world outdoor settings.
                     Additionally, we introduce a novel probabilistic Ranking method that integrates visual scene context. This study offers new insights for improving gaze classification in natural, dynamic environments.
                     <br>
                    <i style="color: rgb(36, 14, 136);">Submitted</i>
                  </p>
                  <!-- <div class="white-button">
                    <a href="https://drive.google.com/file/d/12nx7o8BOuuUC6pae2A941mmr2yg0VWNB/view?usp=sharing">Poster</a>
                  </div> -->
                  <!-- <div class="white-button">
                    <a href="">Paper</a>
                  </div> -->
                  <!-- <div class="white-button">
                    <a href="https://github.com/arnejad/Gaze-Shift-Compare">Git Repo</a>
                  </div> -->
                </div>
              </div>
            </div>
          </div>


          <div class="left-image-post">
            <div class="row">
              <div class="col-md-4">
                <div class="left-image">
                  <img src="assets/images/spv.gif" alt="SPV-G" />
                </div>
                <div style="margin-top: 10px;">
                  <a href="https://www.visio.org/en-gb/professional/expertise/onderzoeken">
                    <img src="assets/images/logos/visio.png" style="width: 90px;" alt="visio" />
                  </a>
                  <a href="https://www.ru.nl/donders/">
                    <img src="assets/images/logos/donders_logo.svg" style="width: 110px;" alt="donders" />
                  </a>
                </div>
              </div>
              <div class="col-md-8">
                <div class="right-text">
                  <h4>Point-SPV: End-to-End Enhancement of Object Recognition in Simulated Prosthetic Vision using Synthetic Viewing Points</h4>
                  <p style="margin-top: 0px">Ashkan Nejad, <a href="https://www.ru.nl/en/people/kucukoglu-b">Burcu Kucukoglu</a>,
                     <a href="https://www.researchgate.net/profile/Jaap-De-Ruyter-Van-Steveninck">Jaap de Ruyter van Steveninck</a>,
                     <a href="#">Sandra Bedrossian</a>,<a href="https://www.rug.nl/staff/j.h.c.heutink/">Joost Heutink</a>,
                     <a href="https://www.rug.nl/staff/g.a.de.haan/">Gera A. De Haan</a>,
                     <a href="https://www.rug.nl/staff/f.w.cornelissen/">Frans W. Cornelissen</a>,
                     <a href="https://www.ru.nl/personen/gerven-m-van">Marcel van Gerven</a></p>
                  <p>
                    Prosthetic vision systems aim to restore functional sight for visually impaired individuals, but challenges remain in optimizing visual
                     representations. We introduce Point-SPV, a model designed to enhance object recognition and takes an initial step towards incorporating gaze-based optimization.
                     <br>
                    <i style="color: rgb(36, 14, 136);">Published</i>
                  </p>
                  <!-- <div class="white-button">
                    <a href="https://drive.google.com/file/d/12nx7o8BOuuUC6pae2A941mmr2yg0VWNB/view?usp=sharing">Poster</a>
                  </div> -->
                  <div class="white-button">
                    <a href="https://www.frontiersin.org/journals/human-neuroscience/articles/10.3389/fnhum.2025.1549698/">Paper</a>
                  </div>
                  <div class="white-button">
                    <a href="https://github.com/arnejad/E2E-Point-SPV">Git Repo</a>
                  </div>
                </div>
              </div>
            </div>
          </div>



          <div class="left-image-post">
            <div class="row">
              <div class="col-md-4">
                <div class="left-image">
                  <img src="assets/images/ACE-DNV-events.jpg" alt="ACE-DNV" />
                </div>
                <div style="margin-top: 10px;">
                  <a href="https://www.visio.org/en-gb/professional/expertise/onderzoeken">
                    <img src="assets/images/logos/visio.png" style="width: 90px;" alt="BrainSeg" />
                  </a>
                  <a href="http://www.visualneuroscience.nl/">
                    <img src="assets/images/logos/logo-umcg.png" style="width: 90px;" alt="BrainSeg" />
                  </a>
                  <a href="https://www.rug.nl/">
                    <img src="assets/images/logos/rug.png" style="width: 90px;" alt="BrainSeg" />
                  </a>
                </div>
              </div>
              <div class="col-md-8">
                <div class="right-text">
                  <h4>ACE-DNV: Automatic Classification of Gaze Events in Dynamic Natural Viewing </h4>
                  <p style="margin-top: 0px">Ashkan Nejad, <a href="https://www.rug.nl/staff/g.a.de.haan/">Gera de Haan</a>, <a href="https://www.rug.nl/staff/j.h.c.heutink/">Joost Heutink</a>, <a href="https://www.rug.nl/staff/f.w.cornelissen/">Frans Cornelissen</a></p>
                  <p>
                    It is challenging for people with visual field defects to perform daily tasks that rely on having a good visual overview.
                    For helping people with such a condition, an essential step is to quantify their scanning behavior. 
                    However, there are no accurate gaze event detectors that are suitable for use in dynamic natural conditions, limiting research in such settings. ACE-DNV is one of the first eye-movement event classification methods in dynamic and natural viewing. Our method only uses recordings of commercial eye-trackers 
                    We aim to design a gaze-event detector for conditions that allow free head- and body- movements conditions. 
                    <br>
                    <i style="color: rgb(36, 14, 136);">Published</i>
                  </p>
                  
                  <div class="white-button">
                    <a href="https://link.springer.com/article/10.3758/s13428-024-02358-8">Paper</a>
                  </div>
                  <div class="white-button">
                    <a href="https://github.com/arnejad/ACE-DNV">Git Repo</a>
                  </div>
                </div>
              </div>
            </div>
          </div>



          <div class="left-image-post">
            <div class="row">
              <div class="col-md-4">
                <div class="left-image">
                  <img src="assets/images/archetypes.jpg" alt="ACE-DNV" />
                </div>
                <div style="margin-top: 10px;">
                  <a href="https://www.visio.org/en-gb/professional/expertise/onderzoeken">
                    <img src="assets/images/logos/visio.png" style="width: 90px;" />
                  </a>
                  <a href="http://www.visualneuroscience.nl/">
                    <img src="assets/images/logos/logo-umcg.png" style="width: 90px;" />
                  </a>
                  <a href="https://www.rug.nl/">
                    <img src="assets/images/logos/city.png" style="width: 90px;" />
                  </a>
                </div>
              </div>
              <div class="col-md-8">
                <div class="right-text">
                  <h4>Archetypes of Binocular Visual Field Loss and Their Impact on Vision-Related Quality of Life in Glaucoma Patients</h4>
                  <p style="margin-top: 0px"><a href="https://www.researchgate.net/profile/Mehrdad-Gazanchian">Mehrdad Gazanchian</a>, Ashkan Nejad, <a href="https://www.city.ac.uk/about/people/academics/david-crabb">David P. Crabb</a>, <a href="https://www.researchgate.net/profile/Giovanni-Montesano-2">Giovanni Montesano</a>, <a href="https://www.rug.nl/staff/n.m.jansonius/?lang=en">Nomdo M. Jansonius</a></p>
                  <p>
                    Binocular visual field loss impacts vision-related quality of life (VR-QoL),
                     but the link between specific loss patterns and task difficulties remains unclear.
                      We aim to develop archetypes of binocular VF loss and analyze their relationships 
                      with VR-QoL to improve understanding and inform clinical decision-making.
                    <br>
                    <i style="color: rgb(36, 14, 136);">Under prepration</i>
                  </p>
                  
                  <!-- <div class="white-button">
                    <a href="https://link.springer.com/article/10.3758/s13428-024-02358-8">Paper</a>
                  </div> -->
                  <div class="white-button">
                    <a href="https://github.com/LEO-UMCG/IVF_Archetypes">Git Repo</a>
                  </div>
                </div>
              </div>
            </div>
          </div>
          <div class="left-image-post">
            <div class="row">
              <div class="col-md-4">
                <div class="left-image">
                  <img src="assets/images/brainseg.jpg" alt="BrainSeg" />
                </div>
                <div style="margin-top: 10px;">
                  <a href="https://www.ut.ac.ir/en"> 
                    <img src="assets/images/logos/University_of_Tehran_logo.svg" style="width: 60px;" alt="BrainSeg" /> 
                  </a>
                  <a href="https://en.tums.ac.ir/en"> 
                    <img src="assets/images/logos/TUMS.png" style="width: 200px;" alt="BrainSeg" />
                  </a>
                </div>
              </div>
              <div class="col-md-8">
                <div class="right-text">
                  <h4>A Fast and Memory-efficient Brain MRI Segmentatin Framework for Clinical Applications</h4>
                  <p style="margin-top: 0px">Ashkan Nejad, <a href="https://www.researchgate.net/profile/Saeed-Masoudnia-2">Saeed Masoudnia</a>, <a href="https://amtei.tums.ac.ir/en/academic_staff/dr-mohammad-reza-nazem-zadeh/">Mohammad-Reza Nazem-Zadeh</a></p>
                  <p>
                    Current structural brain MRI segmentation methods have limited use in the clinics due to their time and memory consumption. 
                    To address this issue, we customize a memory-efficient (GPU) brain structure segmentation framework based on DNN. 
                    The code is publicly available.
                  </br>
                    <i style="color: rgb(36, 14, 136);">Published in 2022 44th IEEE EMBC</i>
                  </p>
                  <div class="white-button" style="">
                    <a href="https://research.rug.nl/files/240055799/Brain_MRI_Segmentation_EMBC_2022.pdf">Paper</a>
                  </div>
                  <div class="white-button" style="">
                    <a href="https://ieeexplore.ieee.org/document/9871715">IEEEXplore</a>
                  </div>
                  <div class="white-button">
                    <a href="https://github.com/arnejad/FLBS">GitHub Repo</a>
                  </div>
                  
                </div>
              </div>
            </div>
          </div>
          <div class="left-image-post">
            <div class="row">
              <div class="col-md-4">
                <div class="left-image">
                  <img src="assets/images/BraTS.png" alt="Brats" />
                </div>
                <div style="margin-top: 10px;">
                  <a href="https://www.ut.ac.ir/en"> 
                    <img src="assets/images/logos/University_of_Tehran_logo.svg" style="width: 60px;" alt="BrainSeg" /> 
                  </a>
                  <a href="https://en.tums.ac.ir/en"> 
                    <img src="assets/images/logos/TUMS.png" style="width: 200px;" alt="BrainSeg" />
                  </a>
                </div>
              </div>
              <div class="col-md-8">
                <div class="right-text">
                  <h4>A Memory-efficient Deep Framework for Multi-Modal MRI-based Brain Tumor Segmentation</h4>
                  <p style="margin-top: 0px">Nima Hashemi, <a href="https://www.researchgate.net/profile/Saeed-Masoudnia-2">Saeed Masoudnia</a>, Ashkan Nejad, <a href="https://amtei.tums.ac.ir/en/academic_staff/dr-mohammad-reza-nazem-zadeh/">Mohammad-Reza Nazem-Zadeh</a></p>
                  <p>
                    To address the memory limitations in automatic brain tumor segmentation, we utilize several techniques for customizing a memory-efficient yet accurate deep framework based on 2D U-nets.
                    In this framework, the simultaneous multi-label tumor segmentation is decomposed into fusion of sequential binary segmentation tasks.  
                    Experiments on BraTS 2020 showed that our framework almost achieves state-of-the-art results. Dice scores of 0.905, 0.903, and 0.822 for whole tumor, tumor core, and enhancing tumor are accomplished on the testing set.
                  </br>
                  <i style="color: rgb(36, 14, 136);">Published in 2022 44th IEEE EMBC</i>
                  </p>
                  
                  <div class="white-button">
                    <a href="https://pure.rug.nl/ws/portalfiles/portal/593801809/A_Memory_efficient_Deep_Framework_for_Multi_Modal_MRI_based_Brain_Tumor_Segmentation.pdf">Paper</a>
                  </div>
                  <div class="white-button">
                    <a href="https://ieeexplore.ieee.org/document/9871726">IEEEXplore</a>
                  </div>
                  <div class="white-button">
                    <a href="https://github.com/Nima-Hs/BraTS">GitHub Repo</a>
                  </div>
                  
                </div>
              </div>
            </div>
          </div>
          <div class="left-image-post">
            <div class="row">
              <div class="col-md-4">
                <div class="left-image">
                  <img src="assets/images/CBIR2.jpg" alt="CBIR" />
                </div>
                <div style="margin-top: 10px;">
                  <a href="iasbs.ac.ir"> 
                    <img src="assets/images/logos/iasbs.png" style="width: 200px;" alt="IASBS" /> 
                  </a>
                  <a href="https://www.usu.edu/cs/"> 
                    <img src="assets/images/logos/utah.png" style="width: 60px;" alt="USU" />
                  </a>
                </div>
              </div>
              <div class="col-md-8">
                <div class="right-text">
                  <h4>Saliency Map-based Image Retrieval using Krawtchouk Moments</h4>
                  <p style="margin-top: 0px">Ashkan Nejad, <a href="https://scholar.google.com/citations?user=24aT0IEAAAAJ&hl=en">Mohammad Reza Faraji</a>, <a href="https://www.usu.edu/cs/people/XiaojunQi/">Xiaojun Qi</a></p>
                  <p>
                    CBIR has been widely used to find the similar images based on the semantic meaning of the content. 
                    In this project at IASBS, we have focused on proposing a new method for Image Retrieval by using Saliency maps and Krawtchouk Moments. 
                    The supervisor of this project is Dr. Mohammadreza Faraji.
                    <!-- <br> -->
                    <!-- <i style="color: rgb(36, 14, 136);">Under Review</i> -->
                  </p>
                  <div class="white-button">
                    <a href="https://arxiv.org/abs/2411.08567">ArXiv</a>
                  </div>
                  <!-- <div class="white-button">
                    <a href="">Read More</a>
                  </div> -->
                </div>
              </div>
            </div>
          </div>
          <div class="left-image-post">
            <div class="row">
              <div class="col-md-4">
                <div class="left-image">
                  <img src="assets/images/Helia.png" alt="Helia" />
                </div>
              </div>
              <div class="col-md-8">
                <div class="right-text">
                  <h4>Helia</h4>
                  <p>
                    Helia is a AI-based Electronic Health Recording System which assists physicians in the process of diagnosis and prescribing to prevent medical error. 
                    Helia uses a powerful AI engine with huge amount of data extracted from Medical Hand-books and experiences in other cases. 
                    IK Hospital, one of the biggest in Iran, has been the first to use this project. For more information please visit: helia-care.com
                  </p>
                  <div class="white-button">
                    <a href="www.helia-care.com">Read More</a>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </section>
      

    <!-- Scripts -->
    <!-- Bootstrap core JavaScript -->
    <script src="vendor/jquery/jquery.min.js"></script>
    <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

    <script src="assets/js/isotope.min.js"></script>
    <script src="assets/js/owl-carousel.js"></script>
    <script src="assets/js/lightbox.js"></script>
    <script src="assets/js/custom.js"></script>

  </body>
</html>
